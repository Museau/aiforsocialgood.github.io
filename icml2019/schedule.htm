
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <link rel="icon" href="logo/logo2-icon-small.png">

  <meta property="og:title" content="AI for Social Good Workshop at ICML2019">
  <meta property="og:description" content="A focus on social problems for which artificial intelligence has the potential to offer meaningful solutions.">
  <meta name="description" content="A focus on social problems for which artificial intelligence has the potential to offer meaningful solutions.">

  <meta property="og:keywords" content='artificial intelligence, social problems, healthcare, machine learning, Long Beach,  International Conference on Machine Learning, ICML2019'>
  <meta name="keywords" content="artificial intelligence, social problems, healthcare, machine learning, Long Beach,  International Conference on Machine Learning, ICML2019">
  <meta property="og:image" content="https://aiforsocialgood.github.io/2018/logo/logo2-white.png" />
  <meta property="og:locale" content="en_US" />


    <title>AI for Social Good Workshop ICML2019</title>

  <script src="https://code.jquery.com/jquery-3.3.1.min.js"></script>

  <!-- Bootstrap core CSS -->

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap-theme.min.css">
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124501848-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-124501848-1');
</script>

<script>

function pageScript(tomatch){
  url = window.location.pathname
  s = url.substring(url.lastIndexOf('/')+1)
  return tomatch == s
}

</script>

<link rel="stylesheet" href="style.css?v=1">
<link rel="stylesheet" href="res/hover-min.css" >

<style>

</style>


  </head>

  <body>

    <div class="blog-masthead"  style="font-family: arial">
      <div class="container">
        <nav class="blog-nav">
          <a class="blog-nav-item" href="index.htm">AI for Social Good ICML2019 Workshop</a>
           <a class="blog-nav-item" href="schedule.htm">Schedule</a>

           <a class="blog-nav-item" href="cfp.htm">Call for Papers</a>

        <span class="dropdown">
        <a class="blog-nav-item dropdown-toggle" id="dropdownMenu1" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true" href="#">
          Accepted Papers
          <span class="caret"></span>
        </a>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
          <li><a id="dropdownMenu1_item1" href="acceptedpapers.htm">Short Papers</a></li>
          <li><a id="dropdownMenu1_item2" href="proposals.htm">Problem Introduction</a></li>
        </ul>
      </span>
          <a class="blog-nav-item" href="guidelines_reviewers.htm">Guidelines</a>
          <a class="blog-nav-item" href="organizers.htm">Organizers</a>
          <a class="blog-nav-item" href="pastworkshops.htm">Past Workshops</a>
          <a class="blog-nav-item" href="faq_general.htm">FAQ</a>


          <!--  <a class="blog-nav-item" href="#">Accepted Papers</a>-->
        </nav>
      </div>
    </div>
    <script>

          var url = window.location.href;
          var page = url.split(/[\\/]/).pop();

          $.each($(".blog-nav a"), function(i, e) {
              var p = $(e).attr("href");

              var s1 = page.split("_")[0];
              var s2 = p.split("_")[0];

              if (p==page | s1==s2) {
                if ($(e).hasClass('blog-nav-item')) {
                  $(e).addClass('active');
                }
                else {
                  var id = $(e).attr('id');
                  id = id.split('_')[0];
                  $("#"+id).addClass('active');
                }
              }

          });


    </script>

    <div class="container">


                    <div class="blog-header">
        <h1 class="blog-title">Schedule <br>
          <small>Saturday June 15th

          </small>
          </h1>
      </div>

      <div class="row">

        <div class="col-sm-8 blog-main">

          <div class="blog-post schedule">

            <p>



    

    <div class="schedule-item row">
    <h4>8:45 - 9:00 Welcoming and Poster set-up</h4>

   <p>
        
   </p>

</div>


    

    <div class="schedule-item row">
    <h4>9:00 - 9:05 Opening remarks</h4>

   <p>
        
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/yoshua.jpg"></center>
           <h4 class="speaker-name">Yoshua Bengio</h4>
           <p class="speaker-org">Mila</p>
       </div>

      <p class="speaker-bio">
        Yoshua Bengio is Full Professor of the Department of Computer Science and Operations Research, scientific director of Mila, CIFAR Program co-director of the CIFAR Learning in Machines and Brains program (formerly Neural Computation and Adaptive Perception), scientific director of IVADO and Canada Research Chair in Statistical Learning Algorithms. His main research ambition is to understand principles of learning that yield intelligence. He supervises a large group of graduate students and post-docs. His research is widely cited (over 130000 citations found by Google Scholar in August 2018, with an H-index over 120, and rising fast).
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>9:05 - 9:45 Keynote - Solving societal challenges with AI through partnerships</h4>

   <p>
        Wadhwani AI was inaugurated a little more than a year ago with the mission of bringing the power of AI to address societal challenges, especially among underserved communities throughout the world. We aim to address problems all major domains including health, agriculture, education, infrastructure, and financial inclusion. We are currently working on three solutions (two in health and one in agriculture) and are exploring more areas where we can apply AI for social good.The most important lesson that we have learned during our short stint is the importance of working in close partnership with other stakeholders and players in the social sectors, especially NGOs and Government organizations. In this talk, I will use one case, namely that of developing an AI based approach for Integrated Pest Management (IPM) in Cotton Farming, to describe how this partnership based approach has evolved and been critical to our solution development and implementation.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/anandan.jpg"></center>
           <h4 class="speaker-name">Padmanabhan Anandan</h4>
           <p class="speaker-org">Wadhwani Institute of Artificial Intelligence</p>
       </div>

      <p class="speaker-bio">
        Dr. P. Anandan is the CEO of Wadhwani Institute of Artificial Intelligence. His prior experience includes - Adobe Research Lab India (2016-2017) as a VP for Research and a Distinguished Scientist and Managing Director at Microsoft Research (1997-2014). He was also the founding director of Microsoft Research India which he ran from 2005-2014. 
Earlier stint was at Sarnoff Corporation (1991-1997) as a researcher and an Assistant Professor of Computer Science at Yale University (1987-1991). His primary research area is Computer vision where he is well known for his fundamental and lasting contributions to the problem of visual motion analysis. 
He received his PhD in Computer Science from University of Massachusetts, Amherst in 1987, a Masters in Computer Science from University of Nebraska, Lincoln in 1979 and his B.Tech in Electrical Engineering from IIT Madras, India in 1977. He is a distinguished alumnus of IIT Madras, and UMass, Amherst and is on the Nebraska Hall of Computing. 
His hobbies include playing African drums, writing poems (in Tamil) and travel which makes his work related travel interesting. 
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>9:45 - 9:50 AI Commons</h4>

   <p>
        AI Commons is a collective project whose goal is to make the benefits of AI available to all. Since AI research can benefit from the input of a large range of talents across the world, the project seeks to develop ways for developers and organizations to collaborate more easily and effectively. As a community operating in an environment of trust and problem-solving, AI Commons can empower researchers to tackle the world's important problems using all the possibilities of cutting-edge AI.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/yoshua.jpg"></center>
           <h4 class="speaker-name">Yoshua Bengio</h4>
           <p class="speaker-org">Mila</p>
       </div>

      <p class="speaker-bio">
        Yoshua Bengio is Full Professor of the Department of Computer Science and Operations Research, scientific director of Mila, CIFAR Program co-director of the CIFAR Learning in Machines and Brains program (formerly Neural Computation and Adaptive Perception), scientific director of IVADO and Canada Research Chair in Statistical Learning Algorithms. His main research ambition is to understand principles of learning that yield intelligence. He supervises a large group of graduate students and post-docs. His research is widely cited (over 130000 citations found by Google Scholar in August 2018, with an H-index over 120, and rising fast).
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>9:50 - 10:00 Problem proposal - Detecting Waterborne Debris with Sim2Real and Randomization</h4>

   <p>
        Marine debris pollution is one of the most ubiquitous and pressing environmental issues affecting our oceans today. Clean up efforts such as the Great Pacific Garbage Patch project have been implemented across the planet to combat this problem. However, resources to accomplish this goal are limited, and the afflicted area is vast. To this end, unmanned vehicles that are capable of automatically detecting and removing small-sized debris would be a great complementary approach to existing large-scale garbage collectors. Due to the complexity of fully functioning unmanned vehicles for both detecting and removing debris, in this project, we focus on the detection task as a first step. From the perspective of machine learning, there is an unfortunate lack of sufficient labeled data for training a specialized detector, e.g., a classifier that can distinguish debris from other objects like wild animals. Moreover, pre-trained detectors on other domains would be ineffective while creating such datasets manually would be very costly. Due to the recent progress of training deep models with synthetic data and domain randomization, we propose to train a debris detector based on a mixture of real and synthetic images.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/kris.jpg"></center>
           <h4 class="speaker-name">Kris Sankaran</h4>
           <p class="speaker-org">Mila</p>
       </div>

      <p class="speaker-bio">
        Postdoc at Mila working with Yoshua Bengio on problems related to Humanitarian AI. He is generally interested in ways to broaden the scope of problems studied by the machine learning community and am curious about the ways to bridge statistical and computational thinking.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>10:00 - 10:10 Problem proposal - Conversational agents to address abusive online behaviors</h4>

   <p>
        Technologies to address cyber bullying are limited to detecting and hiding abusive messages. We propose to investigate the potential of conversational technologies for addressing abusers. We will outline directions for studying the effectiveness dialog strategies (e.g., to educate or deter abusers, or keep them busy with chatbots rather than their victims) and for initiating new research on chatbot-mediated mitigation of online abuse.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/emma_beauxis.jpg"></center>
           <h4 class="speaker-name">Emma Beauxis-Aussalet</h4>
           <p class="speaker-org">Amsterdam University of Applied Science</p>
       </div>

      <p class="speaker-bio">
        Emma Beauxis-Aussalet is a Senior Track Associate at the Digital Society School of Amsterdam University of Applied Science, where she investigates how data-driven technologies can be applied for the best interests of society. She holds a PhD on classification errors and biases from Utrecht University. Her interests include ethical and explainable AI, data literacy in the general public, and the synergy between human & artificial intelligence to tackle job automation.

      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>10:10 - 10:20 Problem proposal - Computer Vision For Food Quality: The Case of Injera</h4>

   <p>
        The use of Teff as an exclusive crop for making Injera, Ethiopian national staple, has changed overtime.Driven by the ever increasing price of Teff, producers have added other ingredients, of which some are good (maze and rice), while others are not. Hence, households opting for the industrial solution of Injera, are disturbed by the fact that hey can not figure out what exactly is contained in their Injera. Thousands of local producers and local shopkeepers work together to make fresh Injera available to millions around the country. However, consumers are finding it more and more difficult to find a safe Injera for purchase. This injera is usually sold unpacked, unlabeled and in an unsafe way through local shops. This being so, consumers face more and more health risks, all the more as it is impossible to evaluate the ingredients contained in the Injera they are buying There are two kinds of risks: (a) the local producers might try to reduce the cost by using cheap ingredients, including risky additives, and (b) the shops might sell expired Injera warmed up. We discuss here the growing food safety problem faced by millions of Injera consumers in Ethiopia, and the possibility of using AI to solve this problem.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/wende.png"></center>
           <h4 class="speaker-name">Wondimagegnhue Tsegaye</h4>
           <p class="speaker-org">Addis Ababa University</p>
       </div>

      <p class="speaker-bio">
        Wondimagegnehu is a master’s student in Information Science at Addis Ababa University. He is working on a master's thesis in learning an optimal representation of word structure for morphological complex languages under a constrained settings: limited training data and human supervision. He is interested in exploring research challenges in using AI on a social setting.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>10:20 - 10:30 Problem proposal - AI for Mitigating Effects of Climate and Weather Changes in Agriculture</h4>

   <p>
        In recent years, floods, landslides and droughts have become an annual occurrence in Sri Lanka. Despite the efforts made by the government and other entities, these natural disasters remain challenging mainly to the people who live in high risk areas. It is also crucial to predict such disasters early on to facilitate evacuation of people living in these areas. Furthermore, Sri Lankan economy largely depends on agriculture, yet this sector still remains untouched by recent advancements of AI and other predictive analytics techniques. The solution is to develop an AI based platform that generates insights from emerging data sources. It will be modular, extensible and open source. Similar to any other real world AI system, the end solution will consist of multiple data pipelines to extract data, analyze and present results through APIs. The presentation layer will be a public API that can be consumed through a portal such as Disaster Management Centre of Sri Lanka.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/Narmada.jpg"></center>
           <h4 class="speaker-name">Narmada Balasooriya</h4>
           <p class="speaker-org">ConscientAI Labs</p>
       </div>

      <p class="speaker-bio">
        Narmada is research engineer at ConscientAI Labs based in Sri Lanka. She is also a visiting
research student at the Memorial University of Newfoundland, Canada. She is interested in
research on climate change and effects of it on human lifestyle and Deep Learning for
Computer Vision.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>10:30 - 11:00 Break / Poster Session</h4>

   <p>
        
   </p>

</div>


    

    <div class="schedule-item row">
    <h4>11:00 - 11:40 Keynote - AI for Ecology and Conservation</h4>

   <p>
        AI can help solve big data and decision-making problems to understand and protect the environment. I’ll survey several projects the area and discuss how to approach environmental problems using AI. The Dark Ecology project uses weather radar and machine learning to unravel mysteries of bird migration. A surprising probabilistic inference problem arises when analyzing animal survey data to monitor populations. Novel optimization algorithms can help reason about dams, hydropower, and the ecology of river networks.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/daniel_sheldon.jpg"></center>
           <h4 class="speaker-name">Daniel Sheldon</h4>
           <p class="speaker-org">University of Massachusetts Amherst & Mount Holyoke College</p>
       </div>

      <p class="speaker-bio">
        Daniel Sheldon is an Assistant Professor of Computer Science at the University of Massachusetts Amherst and Mount Holyoke College. His research investigates fundamental problems in machine learning and AI motived by large-scale environmental data, dynamic ecological processes, and real-world network phenomena.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>11:40 - 11:50 Contributed talk - Using AI for Economic Upliftment of Handicraft Industry</h4>

   <p>
        The handicraft industry is a strong pillar of Indian economy which provides large-scale employment opportunities to artisans in rural and underprivileged communities. However, in this era of globalization, diverse modern designs have rendered traditional designs old and monotonous, causing an alarming decline of handicraft sales. In this talk, we will discuss our approach leveraging techniques like GANs, Color Transfer, Pattern Generation etc. to generate contemporary designs for two popular Indian handicrafts - Ikat and Block Print. The resultant designs are evaluated to be significantly more likeable and marketable than the current designs used by artisans.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/sonam_damani.jpg"></center>
           <h4 class="speaker-name">Sonam Damani</h4>
           <p class="speaker-org">Microsoft</p>
       </div>

      <p class="speaker-bio">
        Sonam Damani is an Applied Scientist in Microsoft, India where she has worked on several projects in the field of AI and Deep Learning, including Microsoft's human-like-chatbot Ruuh, Cortana personality, novel art generation using AI, Bing search relevance, among others. In the past year, she has co-authored a bunch of publications in the field of conversational AI and AI creativity that were presented in NeurIPS, WWW and CODS-COMAD.

      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>11:50 - 12:00 Contributed talk - Deep Neural Networks Improve Radiologists' Performance in Breast Cancer Screening</h4>

   <p>
        We present a deep CNN for breast cancer screening exam classification, trained and evaluated on over 200,000 exams (over 1,000,000 images). Our network achieves an AUC of 0.895 in predicting whether there is a cancer in the breast, when tested on the screening population. We attribute the high accuracy of our model to a two-stage training procedure, which allows us to use a very high-capacity patch-level network to learn from pixel-level labels alongside a network learning from macroscopic breast-level labels. To validate our model, we conducted a reader study with 14 readers, each reading 720 screening mammogram exams, and find our model to be as accurate as experienced radiologists when presented with the same data. Finally, we show that a hybrid model, averaging probability of malignancy predicted by a radiologist with a prediction of our neural network, is more accurate than either of the two separately.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/krzysztof.jpg"></center>
           <h4 class="speaker-name">Krzysztof Jerzy Geras</h4>
           <p class="speaker-org">New York University</p>
       </div>

      <p class="speaker-bio">
        Krzysztof is an assistant professor at NYU School of Medicine and an affiliated faculty at NYU Center for Data Science. His main interests are in unsupervised learning with neural networks, model compression, transfer learning, evaluation of machine learning models and applications of these techniques to medical imaging. He previously did a postdoc at NYU with Kyunghyun Cho, a PhD at the University of Edinburgh with Charles Sutton and an MSc as a visiting student at the University of Edinburgh with Amos Storkey. His BSc is from the University of Warsaw.
      </p>
   
    </div>
    
   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/Nan.jpg"></center>
           <h4 class="speaker-name">Nan Wu</h4>
           <p class="speaker-org">New York University</p>
       </div>

      <p class="speaker-bio">
        Nan is a PhD student at NYU Center for Data Science. She is interested in data science with application to healthcare and currently working on medical image analysis. Before joining NYU, she graduated from School for Gifted Young, University of Science and Technology of China, receiving B.S in Statistics and B.A. in Business Administration.


      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>12:00 - 14:00 Lunch - on your own</h4>

   <p>
        
   </p>

</div>


    

    <div class="schedule-item row">
    <h4>14:00 - 14:30 Keynote: AI for Whose Social Good?</h4>

   <p>
        Luke Stark will discuss two recent papers (Greene, Hoffmann & Stark 2019; Stark & Hoffmann 2019) that use discursive analysis to examine a) recent high-profile value statements endorsing ethical design for artificial intelligence and machine learning and b) professional ethics codes in computer science, statistics, and other fields. Guided by insights from Science and Technology Studies, values in design, and the sociology of business ethics, he will discuss the grounding assumptions and terms of debate that shape current conversations about ethical design in data science and AI. He will also advocate for an expanded view of expertise in understanding what ethical AI/ML/AI for Social Good should mean.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/LukeStark.jpeg"></center>
           <h4 class="speaker-name">Luke Stark</h4>
           <p class="speaker-org">Microsoft Research</p>
       </div>

      <p class="speaker-bio">
        Luke Stark is a Postdoctoral Researcher in the Fairness, Accountability, Transparency and Ethics (FATE) Group at Microsoft Research Montreal, and an Affiliate of the Berkman Klein Center for Internet & Society at Harvard University. Luke holds a PhD from the Department of Media, Culture, and Communication at New York University, and an Honours BA and MA in History from the University of Toronto. Trained as a media historian, his scholarship centers on the interconnected histories of artificial intelligence (AI) and behavioral science, and on the ways the social and ethical contexts of AI are changing how we work, communicate, and participate in civic life.  
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>14:30 - 15:00 Keynote: How to Volunteer as an AI Researcher</h4>

   <p>
        Over the past six years, Will High has volunteered his expertise as a data scientist to various nonprofits and civic causes. He's contributed to work on homelessness, improving charter schools and optimizing water distribution. Will will talk about his experience doing pro-bono work with DataKind, a global nonprofit based in New York that connects leading social change organizations with data science talent to collaborate on cutting-edge analytics and advanced algorithms developed to maximize social impact. He'll comment on DataKind's mission, how to structure effective pro-bono engagements, and broader principles of the pro bono model applied to machine learning, analytics and engineering.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/WilliamHigh.png"></center>
           <h4 class="speaker-name">William High</h4>
           <p class="speaker-org">Joymode</p>
       </div>

      <p class="speaker-bio">
        Will is a data science executive at Joymode in Los Angeles and works with DataKind as Data Ambassador, consultant and facilitator. Will was previously a Senior Data Scientist at Netflix. He holds a PhD in physics from Harvard.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>15:00 - 15:30 Break / Poster Session</h4>

   <p>
        
   </p>

</div>


    

    <div class="schedule-item row">
    <h4>15:30 - 15:50 Poster Session</h4>

   <p>
        
   </p>

</div>


    

    <div class="schedule-item row">
    <h4>15:50 - 16:20 Keynote: Creating constructive change and avoiding unintended consequences from machine learning</h4>

   <p>
        This talk will give an overview of some of the known failure modes that are leading to unintended consequences in AI development, as well as research agendas and initiatives to mitigate them, including a number that are underway at the Partnership on AI (PAI).  Important case studies include the use of algorithmic risk assessment tools in the US criminal justice system, and the side-effects that are caused by using deliberate or unintended optimization processes to design high-stakes technical and bureaucratic system. These are important in their own right, but they are also important contributors to conversations about social good applications of AI, which are also subject to significant potential for unintended consequences.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/Peter_Eckersley.jpg"></center>
           <h4 class="speaker-name">Peter Eckersley</h4>
           <p class="speaker-org">Partnership on AI</p>
       </div>

      <p class="speaker-bio">
        Peter Eckersley is Director of Research at the <a href="https://partnershiponai.org/">Partnership on AI</a>, a collaboration between the major technology companies, civil society and academia to ensure that AI is designed and used to benefit humanity. He leads PAI's research on machine learning policy and ethics, including projects within PAI itself and projects in collaboration with the Partnership's extensive membership. Peter's AI research interests are broad, including <a href="https://eff.org/ai/metrics">measuring progress in the field</a>, figuring out how to translate ethical and safety concerns <a href="https://arxiv.org/abs/1901.00064">into mathematical constraints</a>, finding the right <a href="http://www.aies-conference.com/wp-content/papers/main/AIES-19_paper_147.pdf">metaphors and ways of thinking</a> about AI development, and setting sound policies around high-stakes applications such as <a href="https://www.eff.org/deeplinks/2018/03/some-easy-things-we-could-do-make-all-autonomous-cars-safer-faster">self-driving vehicles</a>, <a href="https://www.partnershiponai.org/wp-content/uploads/2019/04/Report-on-Algorithmic-Risk-Assessment-Tools.pdf">recidivism prediction</a>, <a href="https://www.eff.org/deeplinks/2016/08/darpa-cgc-safety-protocol">cybersecurity</a>, and <a href="https://www.eff.org/deeplinks/2018/08/eff-white-paper-how-militaries-should-use-ai">military applications of AI</a>.

Prior to joining PAI, Peter was Chief Computer Scientist for the <a href="https://www.eff.org/">Electronic Frontier Foundation</a>. At EFF he lead a team of technologists that launched numerous computer security and privacy projects including <a href="https://www.eff.org/deeplinks/2014/11/certificate-authority-encrypt-entire-web">Let's Encrypt</a> and <a href="https://certbot.eff.org/">Certbot</a>, <a href="https://panopticlick.eff.org/">Panopticlick</a>, <a href="https://www.eff.org/https-everywhere">HTTPS Everywhere</a>, the <a href="https://eff.org/observatory">SSL Observatory</a> and <a href="https://www.eff.org/pb">Privacy Badger</a>; they also worked on diverse Internet policy issues including campaigning to preserve <a href="https://openwireless.org/">open wireless networks</a>; fighting to <a href="https://www.eff.org/deeplinks/2012/05/apples-crystal-prison-and-future-open-platforms">keep modern computing platforms open</a>; helping to <a href="https://www.eff.org/deeplinks/2010/09/open-letter">start</a> the <a href="https://www.youtube.com/watch?v=Fgh2dFngFsg">campaign</a> against the SOPA/PIPA <a href="https://www.eff.org/issues/coica-internet-censorship-and-copyright-bill">Internet blacklist legislation</a>; and running the first controlled tests to confirm that Comcast was <a href="https://www.eff.org/wp/packet-forgery-isps-report-comcast-affair">using forged reset packets to interfere with P2P protocols</a>. 

Peter holds a PhD in computer science and law from the University of Melbourne; his research focused on the practicality and desirability of using alternative compensation systems to legalize P2P file sharing and similar distribution tools while still paying authors and artists for their work. He currently serves on the board of the <a href="https://letsencrypt.org/">Internet Security Research Group</a> and the Advisory Council of the <a href="https://opentech.fun/">Open Technology Fund</a>; he is an Affiliate of the <a href="https://cisac.fsi.stanford.edu/">Center for International Security</a> and Cooperation at Stanford University and a Distinguished Technology Fellow at <a href="https://eff.org/">EFF</a>.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>16:20 - 16:30 Contributed talk - Learning Global Variations in Outdoor PM_2.5 Concentrations with Satellite Images</h4>

   <p>
        The World Health Organization identifies outdoor fine particulate air pollution (PM2.5) as a leading risk factor for premature mortality globally. As such, understanding the global distribution of PM2.5 is an essential precursor towards implementing pollution mitigation strategies and modelling global public health. Here, we present a convolutional neural network based approach for estimating annual average outdoor PM2.5 concentrations using only satellite images. The resulting model achieves comparable performance to current state-of-the-art statistical models.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/AI4SG_KrisYHong.jpg"></center>
           <h4 class="speaker-name">Kris Y Hong</h4>
           <p class="speaker-org">McGill University</p>
       </div>

      <p class="speaker-bio">
        Kris is a research assistant and prospective PhD student in the Weichenthal Lab at McGill University, in Montreal, Canada. His interests lie in applying current statistical and machine learning techniques towards solving humanitarian and environmental challenges. Prior to joining McGill, he was a data analyst at the British Columbia Centre for Disease Control while receiving his B.Sc. in Statistics from the University of British Columbia. 
      </p>
   
    </div>
    
   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/AI4SG_PedroOPinheiro.png"></center>
           <h4 class="speaker-name">Pedro O Pinheiro</h4>
           <p class="speaker-org">Element AI</p>
       </div>

      <p class="speaker-bio">
        Dr. Pinheiro is a research scientist at Element AI, in Montreal, Canada. His research focuses on computer vision, machine learning, and their intersection. He finished his PhD in 2017 at École Polytechnique Fédérale de Lausanne (EPFL), in Switzerland, under the supervision of Ronan Collobert (and working closely with Piotr Dollar from FAIR). During his PhD, his work focused mostly on large-scale image segmentation problems using deep learning techniques. Currently, he is interested in learning with less supervision and how to leverage knowledge from one task to another.
      </p>
   
    </div>
    
   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/AI4SG_ScottWeichenthal.jpeg"></center>
           <h4 class="speaker-name">Scott Weichenthal</h4>
           <p class="speaker-org">McGill University</p>
       </div>

      <p class="speaker-bio">
        Dr. Weichenthal is an Assistant Professor in the Department of  Epidemiology, Biostatistics, and Occupational Health at McGill University in Montreal, Canada. His research program is dedicated to identifying and evaluating environmental risk factors for chronic diseases such as cancer and cardiovascular disease. His current research is focused on the use of deep learning models in estimating environmental exposures on both a local and global scale.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>16:30 - 16:40 Contributed talk - Pareto Efficient Fairness for Skewed Subgroup Data</h4>

   <p>
        As awareness of the potential for learned models to amplify existing societal biases increases, the field of ML fairness has developed mitigation techniques. A prevalent method applies constraints, including equality of performance, with respect to subgroups defined over the intersection of sensitive attributes such as race and gender. Enforcing such constraints when the subgroup populations are considerably skewed with respect to a target can lead to unintentional degradation in performance, without benefiting any individual subgroup, counter to the United Nations Sustainable Development goals of reducing inequalities and promoting growth.  In order to avoid such performance degradation while ensuring equitable treatment to all groups, we propose Pareto-Efficient Fairness (PEF), which identifies the operating point on the Pareto curve of subgroup performances closest to the fairness hyperplane. Specifically, PEF finds a Pareto Optimal point which maximizes multiple subgroup accuracy measures. The algorithm scalarizes using the adaptive weighted metric norm by iteratively searching the Pareto region of all models enforcing the fairness constraint. PEF is backed by strong theoretical results on discoverability and provides domain practitioners finer control in navigating both convex and non-convex accuracy-fairness trade-offs. Empirically, we show that PEF increases performance of all subgroups in skewed synthetic data and UCI datasets.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/ananth.jpg"></center>
           <h4 class="speaker-name">Ananth Balashankar</h4>
           <p class="speaker-org">NYU, Google AI</p>
       </div>

      <p class="speaker-bio">
        Ananth Balashnkar is a 2nd year Ph.D student in Computer Science advised by Prof. Lakshminarayanan Subramanian at NYU's Courant Institute of Mathematical Sciences. He is currently interested in Interpretable Machine Learning and the challenges involved in applying machine perception for the domains of policy, privacy, economics and healthcare.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>16:40 - 16:50 Contributed talk - Crisis Sub-Events on Social Media: A Case Study of Wildfires</h4>

   <p>
        Social media has been extensively used for crisis management. Recent work examines possible sub-events as a major crisis unfolds. In this project, we first propose a framework to identify sub-events from tweets. Then, leveraging 4 California wildfires in 2018-2019 as a case study, we investigate how sub-events cascade based on existing hypotheses drawn from the disaster management literature, and find that most hypotheses are supported on social media, e.g., fire induces smoke, which causes air pollution, which later harms health and eventually affects the healthcare system. In addition, we discuss other unexpected sub-events that emerge from social media.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/alex_jaimes.jpg"></center>
           <h4 class="speaker-name">Alejandro (Alex) Jaimes</h4>
           <p class="speaker-org">Dataminr</p>
       </div>

      <p class="speaker-bio">
        Alex is Chief Scientist and SVP of AI at Dataminr. Alex has 15+ years of intl. experience in research and product impact at scale. He has published 100+ technical papers in top-tier conferences and journals in diverse topics in AI and has been featured widely in the press (MIT Tech review, CNBC, Vice, TechCrunch, Yahoo! Finance, etc.). He has given 80+ invited talks (AI for Good Global Summit (UN, Geneva), the Future of Technology Summit, O’Reilly (AI, Strata, Velocity), Deep Learning Summit, etc.). Alex is also an Endeavor Network mentor (which leads the high-impact entrepreneurship movement around the world), and was an early voice in Human-Centered AI (Computing). He holds a Ph.D. from Columbia U.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>16:50 - 17:00 Contributed talk : Towards Detecting Dyslexia in Children's Handwriting Using Neural Networks</h4>

   <p>
        Dyslexia is a learning disability that hinders a person's ability to read. Dyslexia needs to be caught early, however, teachers are not trained to detect dyslexia and screening tests are used inconsistently. We propose (1) two new data sets of handwriting collected from children with and without dyslexia amounting to close to 500 handwriting samples, and (2) an automated early screening technique to be used in conjunction with current approaches, to accelerate the detection process. Preliminary results suggest our system out-performs teachers.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/katie_spoon.png"></center>
           <h4 class="speaker-name">Katie Spoon</h4>
           <p class="speaker-org">Indiana University</p>
       </div>

      <p class="speaker-bio">
        Katie recently completed her B.S./M.S. in computer science from Indiana University with minors in math and statistics, and with research interests in anomaly detection, computer vision, data visualization, and applications of computer vision to health and education, like her senior thesis detecting dyslexia with neural networks. She worked at IBM Research in the summer of 2018 on neuromorphic computing, and will be returning there full-time. She hopes to potentially get a PhD and become a corporate research scientist.
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>17:00 - 17:50  Panel : Bridging Critics and Designers of Socially Impactful AI</h4>

   <p>
        We will explore how AI systems can be designed and evaluated in a ways that include voices beyond tech. How can systems be designed in a participatory way? How can real problems be addressed with AI technology, without lapsing into solutionism? How do best practices in development and governance vary across contexts? We will consider these questions and others, in an effort to better characterize and control the social impacts of AI.
   </p>

   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/mwiza_simbeye.jpg"></center>
           <h4 class="speaker-name">Mwiza Simbeye</h4>
           <p class="speaker-org">African Leadership University</p>
       </div>

      <p class="speaker-bio">
        Mwiza Simbeye is a tech enthusiast and aficionado who is driven by passion for change. He is a computer science student at the African Leadership University and is currently leading an AI Lab at the university; to foster research and development for AI at the university to solve common problems on the continent under agriculture, healthcare and transport. He is also co-founder of (<a href="http://www.agripredict.com">http://www.agripredict.com</a>) and a mentee under the Google AI Mentorship Program.
      </p>
   
    </div>
    
   
  
    <div class="speaker row">
       <div class="col-xs-3 person">
        
           <center><img class="img-circle hvr-buzz"
           src="img/phebe.jpg"></center>
           <h4 class="speaker-name">Phebe Vayanos</h4>
           <p class="speaker-org">University of Southern California</p>
       </div>

      <p class="speaker-bio">
        Phebe Vayanos is Assistant Professor of Industrial & Systems Engineering and Computer Science at the University of Southern California, and Associate Director of the CAIS Center for Artificial Intelligence in Society. Her research aims to address fundamental questions in data-driven optimization (aka prescriptive analytics) with aim to tackle real-world decision- and policy-making problems in uncertain and adversarial environments. 
      </p>
   
    </div>
    
</div>


    

    <div class="schedule-item row">
    <h4>17:50 - 18:00 Open announcement and Best Paper Award</h4>

   <p>
        
   </p>

</div>



<script>
$(function(){

	$(".schedule-item ").hover( function(){
		$( this ).css("background-color", "#eeeeee");
	}, function(){
		$( this ).css("background-color", "white");
	} );

});


</script>


            </p>
          </div><!-- /.blog-post -->


                    </div><!-- /.blog-main -->

        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">

          <div class="dates sidebar-module sidebar-module-inset">
          <center><img src="logo/logo2.png" style="width:100%;"/></center>

<p><b>Deadline for submissions <span style='color:#c8243e;'>*EXTENDED*</span>: <br>April 26th 2019<br> 11:59PM ET</b></p>
<p>Notification of acceptance: <br>May 18th 2019</p>
<p>Camera-ready submission: <br>May 31st 2019</p>
<p>Poster submission: <br>June 7th 2019</p>
<p>Workshop date:
<br>June 15th, 2019
<br>Onsite ICML:
<br>(<a target="_blank" href="https://www.google.com/maps/search/Long+Beach+Convention+Center,+Long+Beach,+California">Map: Long Beach Convention Center, Long Beach, California</a>)
<br> Room 104 B
</p>
<p>Contact:<br><a href="mailto:aisg2019.icml.contact@gmail.com">aisg2019.icml.contact@gmail.com</a> </p>




          </div>
          <div class="sidebar-module">
            <h4>Sponsors</h4>
            <ol class="list-unstyled">
            
              

              <li>Organizer<br>
                <a href="">
                  <img class="sponsorlogo" src="other-logos/mila.png" alt="mila">
                  </img>
                </a>
                <br>
             
              </li>

            </ol>
          </div>

        </div><!-- /.blog-sidebar -->

      </div><!-- /.row -->

    </div><!-- /.container -->


    <footer class="blog-footer">
      <p>AI for Social Good Workshop ICML2019</p>
      <p>Contact:  <a href="mailto:aisg2019.icml.contact@gmail.com">aisg2019.icml.contact@gmail.com</a> </p>
      <p>Code of Conduct: <a href="https://icml.cc/public/CodeOfConduct">ICML Code of Conduct</a></p>
      <br><small>*not affiliated with the AI for Social Good Foundation</small>
    </footer>

  </body>
</html>
